model:
  # OpenGVLab/InternVL3_5-2B-hf
  OpenGVLab/InternVL3-2B-hf
  # OpenGVLab/InternVL3_5-1B-hf

prompt:
  You are a sign language to gloss translator. Each video has a singular word being signed. Please give the word/gloss of the sign gesture performed by the person in the video using just one word only.
  # What is the single sign language word being performed in this video? Respond with only the word in lowercase.
  # For example if the sign is "hello",  respond with "hello". Your response must be limited to just one word without any additional explanation or context.

dataset_path:
  # ../finetune/data_engineering/datasets/test_data.json
  # ../finetune/data_engineering/datasets/wlasl_cleaned.json  # Original (contains corrupted videos)
  ../finetune/data_engineering/datasets/wlasl_validated.json # Validated (corrupted videos removed)

training_arguments:
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 16
  dataloader_num_workers: 2
  learning_rate: 0.00005
  warmup_steps: 100
  label_smoothing_factor: 0.1
  num_train_epochs: 15

lora_config:
  r: 16
  lora_alpha: 32
  dropout: 0.1
